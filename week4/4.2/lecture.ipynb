{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('http://asimjalis.github.io/ipyn-ext/js/ipyn-present.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "This file was auto-generated from markdown using notedown.\n",
    "Instead of modifying the ipynb modify the markdown source. \n",
    "-->\n",
    "\n",
    "<h1 class=\"tocheading\">Hive</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "Hive\n",
    "====\n",
    "\n",
    "Why Hive \n",
    "--------\n",
    "\n",
    "- Instead of writing MapReduce programs what if we could write SQL.\n",
    "\n",
    "- Hive lets you write MapReduce programs in SQL.\n",
    "\n",
    "- This is then translated to MapReduce on the fly.\n",
    "\n",
    "Hive Example\n",
    "------------\n",
    "\n",
    "```sql\n",
    "SELECT user.*\n",
    "FROM user\n",
    "WHERE user.active = 1;\n",
    "```\n",
    "\n",
    "Hive\n",
    "----\n",
    "\n",
    "- Hive was developed at Facebook.\n",
    "\n",
    "- It translates SQL to generate MapReduce code.\n",
    "\n",
    "- Its dialect of SQL is called HiveQL.\n",
    "\n",
    "- Data scientists can use SQL instead of MapReduce to process data.\n",
    "\n",
    "Why Hive\n",
    "--------\n",
    "\n",
    "How can we analyze Big Data without writing MapReduce jobs?\n",
    "\n",
    "- Apache Hive runs SQL queries against large datasets.\n",
    "\n",
    "- Datasets can be in HDFS, S3, and other Hadoop-compatible filesystems.\n",
    "\n",
    "- Used for queries against data without writing Java/Python code.\n",
    "\n",
    "- Used for ad hoc queries against data without schemas.\n",
    "\n",
    "\n",
    "Big Data SQL\n",
    "-------------\n",
    "\n",
    "What other Big Data SQL technologies are out there? Why should I use\n",
    "Hive?\n",
    "\n",
    "Project            |Elevator Pitch\n",
    "-------            |--------------\n",
    "Hive               |Mature, full-featured\n",
    "Hive on Tez        |Hive optimized over MapReduce\n",
    "Hive on Spark      |Hive optimized using Spark\n",
    "Spark SQL          |SQL from scratch on Spark; not as full-featured\n",
    "Shark              |Hive on Spark; abandoned\n",
    "Impala             |SQL without MapReduce using C++; focus on speed\n",
    "Phoenix            |SQL over HBase\n",
    "Trafodion          |SQL engine by HP\n",
    "Presto             |SQL engine by team at HP\n",
    "Drill              |SQL engine by MapR, does well on some queries\n",
    "Flink              |SQL engine with support for realtime data\n",
    "\n",
    "\n",
    "Hive vs RDBMS\n",
    "-------------\n",
    "\n",
    "What are the pros and cons of Hive vs traditional databases (RDBMS)?\n",
    "\n",
    "Hive                                  |RDBMS\n",
    "----                                  |-----\n",
    "HiveQL (subset of SQL-92)             |SQL Interface\n",
    "Schema On Read                        |Schema On Write\n",
    "Write Once, Read Many Times           |Read Many Times, Write Many Times\n",
    "Optimal for static data               |Optimal for dynamic data\n",
    "Transactions not supported            |Transactions supported\n",
    "Highly distributed processing via MR  |Limited distributed processing\n",
    "Handles 100s of Petabytes             |Handles 10s of Terabytes\n",
    "Uses commodity hardware               |Uses proprietary hardware\n",
    "Slow response time                    |Fast response time\n",
    "For batch processing                  |For realtime processing\n",
    "\n",
    "Hive History\n",
    "------------\n",
    "\n",
    "Date           |Version\n",
    "----           |-------\n",
    "Jun 19, 2015   |1.2.1\n",
    "May 11, 2015   |1.2.0\n",
    "Feb 12, 2015   |1.1.0\n",
    "Nov 8, 2014    |0.14\n",
    "Apr 15, 2014   |0.13\n",
    "Oct 17, 2013   |0.12\n",
    "Jun 28, 2013   |0.11\n",
    "Apr 9, 2013    |0.10\n",
    "Dec 16, 2011   |0.8\n",
    "\n",
    "\n",
    "Hive Architecture\n",
    "-----------------\n",
    "\n",
    "![](images/hive-arch.png)\n",
    "\n",
    "- Hive stores metadata about tables in the *MetaStore*\n",
    "\n",
    "- When a SQL or HiveQL query is submitted to Hive it translates it to\n",
    "  MapReduce, using the MetaStore.\n",
    "\n",
    "- Then it submits it to the cluster as a MapReduce job.\n",
    "\n",
    "MetaStore\n",
    "---------\n",
    "\n",
    "What does the MetaStore store?\n",
    "\n",
    "SQL          |MetaStore Maps To\n",
    "---          |-----------------\n",
    "Table Name   |HDFS Directory \n",
    "Column Name  |Column Position\n",
    "Column Type  |Stored Data Type\n",
    "\n",
    "MetaStore Storage\n",
    "-----------------\n",
    "\n",
    "Where does the MetaStore store this information?\n",
    "\n",
    "- By default it stores it in an embedded database called Derby.\n",
    "\n",
    "- Most admins configure it to use MySQL instead.\n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "Why does the MetaStore not use HDFS to store the metadata?\n",
    "</summary>\n",
    "1. The metadata changes constantly.<br>\n",
    "2. The metadata changes every time you add a new table or alter a table.<br>\n",
    "3. HDFS does not allow modifying data.<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "What is the benefit of having a shared MySQL-backed MetaStore instead\n",
    "of each user having his/her own Derby-backed MetaStore?\n",
    "</summary>\n",
    "1. Sharing the MetaStore means everyone uses the same table and column names.<br>\n",
    "2. This makes the SQL consistent and portable across the organization.<br>\n",
    "</details>\n",
    "\n",
    "Hive Shell\n",
    "----------\n",
    "\n",
    "How can I start the Hive shell?\n",
    "\n",
    "- Start VirtualBox.\n",
    "\n",
    "- Select *Hortonworks Sandbox*\n",
    "\n",
    "- Holding down the *Shift* key click *Start*. This brings up the\n",
    "  machine headless.\n",
    "\n",
    "- Connect to it using `ssh -p 2222 root@127.0.0.1`\n",
    "\n",
    "- Use `hadoop` as the password.\n",
    "\n",
    "- Type `hive` to start the Hive shell.\n",
    "\n",
    "Hive Shell Commands\n",
    "-------------------\n",
    "\n",
    "What are some convenient commands in the Hive shell?\n",
    "\n",
    "Command                        |Meaning\n",
    "-------                        |-------\n",
    "`!ls;`                         |List files on local machine\n",
    "`dfs -ls;`                     |List files on HDFS\n",
    "`set mapred.reduce.tasks=32;`  |Set Hadoop configuration parameter\n",
    "`source myscript.sql`          |Run HiveQL script in shell\n",
    "`quit`                         |Exit\n",
    "`exit`                         |Exit\n",
    "\n",
    "\n",
    "Hive Scripting\n",
    "--------------\n",
    "\n",
    "How can I embed Hive into a batch script?\n",
    "\n",
    "Command                              |Meaning\n",
    "-------                              |-------\n",
    "`hive -e 'SELECT * FROM movies'`     |Run SQL and display result\n",
    "`hive -S -e 'SELECT * FROM movies'`  |Run SQL with less logging output and display result\n",
    "`hive -f hive-script.sql`            |Run SQL in `hive-script.sql`\n",
    "\n",
    "\n",
    "Creating Tables\n",
    "===============\n",
    "\n",
    "How To Create Tables\n",
    "--------------------\n",
    "\n",
    "How can I use Hive with data I already have in HDFS?\n",
    "\n",
    "### Upload data to HDFS\n",
    "\n",
    "```sh\n",
    "# Create sales.csv.\n",
    "cat <<'END_OF_DATA' > sales.csv\n",
    "#ID,Date,Store,State,Product,Amount\n",
    "101,2014-11-13,100,WA,331,300.00\n",
    "104,2014-11-18,700,OR,329,450.00\n",
    "102,2014-11-15,203,CA,321,200.00\n",
    "106,2014-11-19,202,CA,331,330.00\n",
    "103,2014-11-17,101,WA,373,750.00\n",
    "105,2014-11-19,202,CA,321,200.00\n",
    "END_OF_DATA\n",
    "\n",
    "# Upload it to HDFS.\n",
    "hadoop fs -rm -r /user/root/sales\n",
    "hadoop fs -mkdir /user/root/sales\n",
    "hadoop fs -put   sales.csv /user/root/sales/part1.csv\n",
    "\n",
    "# Test it was uploaded to HDFS.\n",
    "hadoop fs -ls -R /user/root/sales\n",
    "hadoop fs -cat \"/user/root/sales/*\"\n",
    "```\n",
    "\n",
    "### Create External Table\n",
    "\n",
    "In the Hive shell:\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS  sales;\n",
    "\n",
    "-- Create external table.\n",
    "CREATE EXTERNAL TABLE sales(\n",
    "  id INT,\n",
    "  sale_date STRING,\n",
    "  store INT,\n",
    "  state STRING,\n",
    "  product INT,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/root/sales'\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM sales;\n",
    "```\n",
    "\n",
    "Pop Quiz: Creating Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "Does `CREATE TABLE` have an effect on the MetaStore or on HDFS or\n",
    "both?\n",
    "</summary>\n",
    "1. Creating external tables adds metadata to existing HDFS data.<br>\n",
    "2. It only affects the metastore where the metadata is stored.<br>\n",
    "3. It does not affect the data in HDFS.<br>\n",
    "4. In fact you can create a table with no data in HDFS, and add the\n",
    "data later.<br>\n",
    "</details>\n",
    "\n",
    "Pop Quiz: Creating Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "Can I create multiple external tables on the same data in HDFS?\n",
    "</summary>\n",
    "It would be slightly weird, but yes, you can do this.\n",
    "</details>\n",
    "\n",
    "\n",
    "Internal and External Tables\n",
    "----------------------------\n",
    "\n",
    "What is the difference between *internal* and *external* tables?\n",
    "\n",
    "Command                       |Internal Table               |External Table\n",
    "-------                       |--------------               |--------------\n",
    "`CREATE TABLE`                |Default                      |Requires `EXTERNAL` keyword\n",
    "HDFS Location                 |`/user/hive/warehouse`       |User specifies location\n",
    "`DESCRIBE FORMATTED mytable`  |`TABLE TYPE: MANAGED_TABLE`  |`TABLE TYPE: EXTERNAL_TABLE`\n",
    "`DROP TABLE mytable`          |Deletes metadata + data      |Only deletes metadata\n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "I changed my mind about what I want to call the columns on my\n",
    "internal table. Should I drop the table and start over?\n",
    "</summary>\n",
    "1. Noooo!<br>\n",
    "2. Be very careful with `DROP` and internal tables.<br>\n",
    "3. Use `ALTER` instead.<br>\n",
    "4. Conceptually an internal table is a table for which Hive manages\n",
    "the data.<br>\n",
    "</details>\n",
    "\n",
    "Creating Internal Tables\n",
    "------------------------\n",
    "\n",
    "How can I create an internal table?\n",
    "\n",
    "- Use same syntax as `CREATE TABLE` but leave out `LOCATION` and\n",
    "  `EXTERNAL`.\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS  sales_tmp;\n",
    "\n",
    "-- Create internal table.\n",
    "CREATE TABLE sales_tmp(\n",
    "  id INT,\n",
    "  sale_date STRING,\n",
    "  store INT,\n",
    "  state STRING,\n",
    "  product INT,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM sales_tmp;\n",
    "```\n",
    "\n",
    "Pop Quiz: Internal Tables\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "What are some use cases for internal tables?\n",
    "</summary>\n",
    "1. You can use them for temporary data.<br>\n",
    "2. You can use them to share data between different users.<br>\n",
    "3. The delete-on-drop behavior matches the behavior of traditional databases.<br>\n",
    "</details>\n",
    "\n",
    "Data Ingestion\n",
    "==============\n",
    "\n",
    "Pop Quiz: Why Ingest Data\n",
    "-------------------------\n",
    "\n",
    "<details><summary>\n",
    "What are some use cases for ingesting data?\n",
    "</summary>\n",
    "1. Internal tables start out with no data. After you create the table\n",
    "you have to ingest data into it.<br>\n",
    "2. If you have daily incoming data you have to ingest it into existing\n",
    "tables.<br>\n",
    "</details>\n",
    "\n",
    "How To Ingest Data\n",
    "------------------\n",
    "\n",
    "How can I ingest data into an existing table?\n",
    "\n",
    "### Shell\n",
    "\n",
    "```sh\n",
    "# Upload to HDFS.\n",
    "hadoop fs -rm -r /user/root/sales_tmp\n",
    "hadoop fs -mkdir /user/root/sales_tmp\n",
    "hadoop fs -put   sales.csv /user/root/sales_tmp/part1.csv\n",
    "\n",
    "# Test it was uploaded to HDFS.\n",
    "hadoop fs -ls -R /user/root/sales_tmp\n",
    "hadoop fs -cat \"/user/root/sales_tmp/*\"\n",
    "```\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "-- Load data to Hive.\n",
    "LOAD DATA \n",
    "INPATH '/user/root/sales_tmp' \n",
    "OVERWRITE \n",
    "INTO TABLE sales_tmp;\n",
    "\n",
    "-- Check it is in Hive.\n",
    "SELECT * FROM sales_tmp;\n",
    "```\n",
    "\n",
    "### Shell\n",
    "\n",
    "```bash\n",
    "# Check data in HDFS again.\n",
    "hadoop fs -ls -R /user/root/sales_tmp\n",
    "\n",
    "# Find location of data\n",
    "hive -e \"DESCRIBE FORMATTED sales_tmp;\"\n",
    "```\n",
    "\n",
    "### Hive\n",
    "\n",
    "```bash\n",
    "# Check data in Hive's warehouse dir. \n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_tmp\n",
    "```\n",
    "\n",
    "Pop Quiz: Ingesting Data\n",
    "------------------------\n",
    "\n",
    "<details><summary>\n",
    "What happened to the data in HDFS when we ingested it?\n",
    "</summary>\n",
    "1. `LOAD DATA` moves the data to a Hive-managed directory.<br>\n",
    "2. The data is no longer where you uploaded it.<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "Is the data for the internal tables stored in HDFS or in the metastore?\n",
    "</summary>\n",
    "1. The data is stored in HDFS.<br>\n",
    "2. The data will be too large for the metastore.<br>\n",
    "3. The metastore is stored in MySQL or some other small database.<br>\n",
    "4. It only has metadata: table names, table locations, column names, column types, etc. <br>\n",
    "5. It does not have any table data.<br>\n",
    "</details>\n",
    "\n",
    "\n",
    "Ingesting Data\n",
    "--------------\n",
    "\n",
    "What are the different ways of ingesting data and appending to the table?\n",
    "\n",
    "Commmand                                                 |Path On |Deletes Source\n",
    "--------                                                 |------- |--------------\n",
    "`LOAD DATA INPATH 'path' INTO TABLE t1`                  |HDFS    |Yes\n",
    "`LOAD DATA LOCAL INPATH 'path' INTO TABLE t1`            |Client  |No\n",
    "\n",
    "What are the different ways of ingesting data and overwriting the table?\n",
    "\n",
    "Commmand                                                 |Path On |Deletes Source\n",
    "--------                                                 |------- |--------------\n",
    "`LOAD DATA INPATH 'path' OVERWRITE INTO TABLE t1`        |HDFS    |Yes\n",
    "`LOAD DATA LOCAL INPATH 'path' OVERWRITE INTO TABLE t1`  |Client  |No\n",
    "\n",
    "\n",
    "Pop Quiz: Dropping Tables\n",
    "-------------------------\n",
    "<details><summary>\n",
    "How can I drop a table I no longer need?\n",
    "</summary>\n",
    "1. `DROP TABLE sales;`<br>\n",
    "2. `DROP TABLE IF EXISTS sales;`<br>\n",
    "3. Using `IF EXISTS` is less error prone.<br>\n",
    "</details>\n",
    "\n",
    "Queries\n",
    "=======\n",
    "\n",
    "Select\n",
    "------\n",
    "\n",
    "Now that we have our data in Hive we can run `SELECT` on it.\n",
    "\n",
    "<details><summary>\n",
    "What are all the transactions that were more than $500?\n",
    "</summary>\n",
    "`SELECT * FROM sales WHERE amount > 300;`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I see the first 3 transactions?\n",
    "</summary>\n",
    "`SELECT * FROM sales LIMIT 3;`\n",
    "</details>\n",
    "\n",
    "Functions\n",
    "---------\n",
    "\n",
    "Where can I get more details about all the Hive functions?\n",
    "\n",
    "- [Hive Documentation: Built-in Functions][hive-funcs]\n",
    "\n",
    "- Hive has built-in boolean operators, mathematical functions, string functions,\n",
    "  aggregate functions, and many others.\n",
    "\n",
    "- It also lets you write your custom *User-Define Functions* (UDFs) and\n",
    "  *User-Defined Aggregate Functions* (UDAFs) using Java, Python, and other\n",
    "  languages.\n",
    "\n",
    "[hive-funcs]: https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF\n",
    "\n",
    "Sorting\n",
    "=======\n",
    "\n",
    "Sorting Data\n",
    "------------\n",
    "\n",
    "How can I sort the transactions ordered by amount, highest first.\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;\n",
    "```\n",
    "\n",
    "\n",
    "Sorting Options\n",
    "---------------\n",
    "\n",
    "What are the different ways I can sort data in Hive?\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales ORDER BY amount DESC;\n",
    "SELECT * FROM sales SORT BY amount DESC;\n",
    "SELECT * FROM sales CLUSTER BY amount; \n",
    "SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;\n",
    "```\n",
    "\n",
    "### Order By\n",
    "\n",
    "`ORDER BY x`\n",
    "\n",
    "- Guarantees global ordering\n",
    "- Does by pushing data through one reducer\n",
    "- Does not scale for large datasets\n",
    "\n",
    "### Sort By\n",
    "\n",
    "`SORT BY x`\n",
    "\n",
    "- Orders data at each of N reducers\n",
    "- Each reducer can receive overlapping data range\n",
    "- Produces N or more sorted files with overlapping ranges\n",
    "\n",
    "### Distribute By\n",
    "\n",
    "`DISTRIBUTE BY x` \n",
    "\n",
    "- Each of N reducers gets non-overlapping ranges of x\n",
    "- Does not sort output of each reducer\n",
    "- Produces N or more unsorted files with non-overlapping ranges\n",
    "\n",
    "### Cluster By\n",
    "\n",
    "`CLUSTER BY x` \n",
    "\n",
    "- Each of N reducers gets non-overlapping ranges\n",
    "- Then sorts by those ranges at reducers\n",
    "- Produces global ordering: N or more sorted non-overlapping files \n",
    "- Same as `DISTRIBUTE BY x SORT BY x`\n",
    "- Scalable version of `ORDER BY`\n",
    "- Does not support `DESC`\n",
    "\n",
    "Pop Quiz: Sorting\n",
    "-----------------\n",
    "\n",
    "<details><summary>\n",
    "How should I sort a small sales table on amount?\n",
    "</summary>\n",
    "SELECT * FROM sales ORDER BY amount DESC;\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I sort a large sales table in ascending order?\n",
    "</summary>\n",
    "`SELECT * FROM sales CLUSTER BY amount;`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "How can I sort a large sales table in descending order?\n",
    "</summary>\n",
    "`SELECT * FROM sales DISTRIBUTE BY amount SORT BY amount DESC;`\n",
    "</details>\n",
    "\n",
    "\n",
    "Joins\n",
    "=====\n",
    "\n",
    "Joining Tables\n",
    "--------------\n",
    "\n",
    "How can expand the state IDs to get full state names?\n",
    "\n",
    "### Shell\n",
    "\n",
    "```sh\n",
    "# Create states.csv.\n",
    "cat <<'END_OF_DATA' > states.csv\n",
    "#State,Name\n",
    "CA,California\n",
    "WA,Washington\n",
    "NV,Nevada\n",
    "END_OF_DATA\n",
    "\n",
    "# Upload it to HDFS.\n",
    "hadoop fs -rm -r /user/root/states\n",
    "hadoop fs -mkdir /user/root/states\n",
    "hadoop fs -put   states.csv /user/root/states/part1.csv\n",
    "\n",
    "# Test it was uploaded to HDFS.\n",
    "hadoop fs -ls -R /user/root/states\n",
    "hadoop fs -cat \"/user/root/states/*\"\n",
    "```\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS  states;\n",
    "\n",
    "-- Create external table.\n",
    "CREATE EXTERNAL TABLE states(\n",
    "  state STRING,\n",
    "  name STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/root/states'\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM states;\n",
    "```\n",
    "\n",
    "Joining Tables\n",
    "--------------\n",
    "\n",
    "Join the sales and states tables.\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "SELECT * FROM states JOIN sales ON sales.state = states.state;\n",
    "```\n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "By default did `JOIN` do an inner join or an outer join?\n",
    "</summary>\n",
    "1. This was an inner join.<br>\n",
    "2. Notice that Nevada was not in the output.<br>\n",
    "3. Also Oregon was not in the output.<br>\n",
    "4. Why were these two states missing?<br>\n",
    "</details>\n",
    "\n",
    "Join Details\n",
    "------------\n",
    "\n",
    "Why are joins important?\n",
    "\n",
    "- Joins are indispensible for most interesting data analysis.\n",
    "\n",
    "- Incoming data has references to lookup tables.\n",
    "\n",
    "- Lookup tables map keys to detailed information.\n",
    "\n",
    "- To denormalize the data you join the incoming data with the lookup tables on the keys.\n",
    "\n",
    "Star Schema\n",
    "-----------\n",
    "\n",
    "- Star schema separates business process data into fact tables and\n",
    "  dimension tables.\n",
    "\n",
    "- Facts are measurable, quantitative data about a business For\n",
    "  example, sales transactions. \n",
    " \n",
    "- Dimensions are descriptive attributes related to fact data. For\n",
    "  example, product models, colors, sizes, and salesperson names.\n",
    "\n",
    "- Fact tables are connected to dimension tables through foreign keys.\n",
    "\n",
    "Pop Quiz: Star Schema\n",
    "---------------------\n",
    "\n",
    "<details><summary>\n",
    "How can we combine fact tables with dimension tables?\n",
    "</summary>\n",
    "Using join.<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "Between `sales` and `states` which is the fact table and which is the dimension table? \n",
    "</summary>\n",
    "1. `sales` is the fact table.<br>\n",
    "2. `states` is the dimension table.<br>\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "Between fact and dimension tables, which is likely to be larger?\n",
    "</summary>\n",
    "1. Fact tables are larger and have more churn.<br>\n",
    "2. Dimension tables are smaller and are more stable.<br>\n",
    "3. `sales` will be larger than `states`.<br>\n",
    "</details>\n",
    "\n",
    "Join Optimization\n",
    "-----------------\n",
    "\n",
    "My joins are taking too long. What can I do?\n",
    "\n",
    "- The simplest heuristic is to put the largest table last.\n",
    "\n",
    "- We will talk about other techniques in the next lecture.\n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "Which order should I join `sales` and `states`?\n",
    "</summary>\n",
    "1. `states` should be first.<br>\n",
    "2. `sales` should be last.<br>\n",
    "3. Mneumonic: *LTL* (Largest Table Last).<br>\n",
    "</details>\n",
    "\n",
    "Join Types\n",
    "----------\n",
    "\n",
    "What are the different types of join in Hive?\n",
    "\n",
    "Join Type              |Includes Rows That\n",
    "---------              |------------------\n",
    "`JOIN`                 |Matches found in both table\n",
    "`LEFT OUTER JOIN`      |Match in left table but no match in right\n",
    "`RIGHT OUTER JOIN`     |Match in right table but no match in left\n",
    "`FULL OUTER JOIN`      |Match in either left or right table \n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "Consider this query:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM states JOIN sales ON sales.state = states.state\n",
    "```\n",
    "\n",
    "<details><summary>\n",
    "Which join should I use to get sales transactions with invalid states in this\n",
    "query? \n",
    "</summary>\n",
    "`RIGHT OUTER JOIN`\n",
    "</details>\n",
    "\n",
    "<details><summary>\n",
    "Which join should I use to include states with no sales transactions in this\n",
    "query? \n",
    "</summary>\n",
    "`LEFT OUTER JOIN`\n",
    "</details>\n",
    "\n",
    "\n",
    "Aggregating\n",
    "-----------\n",
    "\n",
    "How can we find the total sales per state?\n",
    "\n",
    "```sql\n",
    "SELECT state, SUM(amount) \n",
    "FROM sales\n",
    "GROUP BY state;\n",
    "```\n",
    "\n",
    "Joins and Aggregating\n",
    "---------------------\n",
    "\n",
    "How can we find the average sales per state for all states in the `states` table?\n",
    "\n",
    "```sql\n",
    "SELECT states.state, AVG(amount) \n",
    "FROM states \n",
    "LEFT OUTER JOIN sales \n",
    "ON sales.state = states.state \n",
    "GROUP BY states.state;\n",
    "```\n",
    "\n",
    "Using Insert/Select to Save Data\n",
    "--------------------------------\n",
    "\n",
    "How can save the results of calculating the average sales?\n",
    "\n",
    "```sql\n",
    "-- Create the table.\n",
    "CREATE TABLE sales_avg(\n",
    "  state STRING,\n",
    "  amount DOUBLE\n",
    ")\n",
    "ROW FORMAT DELIMITED \n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "TBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Insert selected data.\n",
    "INSERT OVERWRITE TABLE sales_avg \n",
    "SELECT states.state, AVG(amount) \n",
    "FROM states \n",
    "LEFT OUTER JOIN sales \n",
    "ON sales.state = states.state \n",
    "GROUP BY states.state;\n",
    "```\n",
    "\n",
    "### Shell \n",
    "\n",
    "```bash\n",
    "# Check that table has data.\n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_avg\n",
    "hadoop fs -cat \"/apps/hive/warehouse/sales_avg/*\"\n",
    "```\n",
    "\n",
    "Insert/Select Details\n",
    "---------------------\n",
    "\n",
    "How can I use `SELECT` to append to a table instead of overwriting it?\n",
    "\n",
    "### Hive\n",
    "\n",
    "```sql\n",
    "-- Append selected data.\n",
    "INSERT INTO TABLE sales_avg \n",
    "SELECT states.state, AVG(amount) \n",
    "FROM states \n",
    "LEFT OUTER JOIN sales \n",
    "ON sales.state = states.state \n",
    "GROUP BY states.state;\n",
    "```\n",
    "\n",
    "### Shell\n",
    "\n",
    "```bash\n",
    "# Check that table has data.\n",
    "hadoop fs -ls -R /apps/hive/warehouse/sales_avg\n",
    "hadoop fs -cat \"/apps/hive/warehouse/sales_avg/*\"\n",
    "```\n",
    "\n",
    "Pop Quiz: Insert/Select Notes\n",
    "-----------------------------\n",
    "\n",
    "<details><summary>\n",
    "What is a quick way to delete the contents of a table?\n",
    "</summary>\n",
    "`INSERT OVERWRITE TABLE sales_avg SELECT * FROM sales_avg WHERE 1 = 0;`\n",
    "</details>\n",
    "\n",
    "Data Formats\n",
    "============\n",
    "\n",
    "Why Data Formats\n",
    "----------------\n",
    "\n",
    "I want to store my data in a more compact binary form and not as text.\n",
    "How can I convert my sales table into Avro?\n",
    "\n",
    "- A common use case for Hive is to convert data between different\n",
    "  formats.\n",
    "\n",
    "- A data format or storage format is a part of the file's metadata.\n",
    "\n",
    "<details><summary>\n",
    "What command can we use to define the data format for a table?\n",
    "</summary>\n",
    "`CREATE TABLE`\n",
    "</details>\n",
    "\n",
    "Defining Table Data Formats\n",
    "---------------------------\n",
    "\n",
    "How can I convert the sales table to Avro?\n",
    "\n",
    "```sql\n",
    "-- Drop table if it exists.\n",
    "DROP TABLE IF EXISTS sales_avro;\n",
    "\n",
    "-- Create external table.\n",
    "CREATE TABLE sales_avro(\n",
    "  id INT,\n",
    "  sale_date STRING,\n",
    "  store INT,\n",
    "  state STRING,\n",
    "  product INT,\n",
    "  amount DOUBLE\n",
    ")\n",
    "STORED AS AVRO;\n",
    "\n",
    "-- Insert data.\n",
    "INSERT OVERWRITE TABLE sales_avro\n",
    "SELECT * \n",
    "FROM sales;\n",
    "\n",
    "-- Select table to test.\n",
    "SELECT * FROM sales_avro;\n",
    "```\n",
    "\n",
    "Storage Formats\n",
    "---------------\n",
    "\n",
    "What storage formats can I define for my tables?\n",
    "\n",
    "In `CREATE TABLE` or `CREATE EXTERNAL TABLE` you can specify the\n",
    "format for your data.\n",
    "\n",
    "Storage Format             |Meaning\n",
    "--------------             |-------\n",
    "`STORED AS TEXTFILE`       |Stored as text (default)\n",
    "`STORED AS PARQUET`        |Stored as Parquet\n",
    "`STORED AS AVRO`           |Stored as Avro\n",
    "`STORED AS SEQUENCEFILE`   |Stored as SequenceFile\n",
    "`STORED AS ORC`            |Stored as ORC\n",
    "\n",
    "\n",
    "Pop Quiz\n",
    "--------\n",
    "\n",
    "<details><summary>\n",
    "What is an easy way to convert CSV files to Parquet?\n",
    "</summary>\n",
    "1. Define table 1 using `STORED AS TEXTFILE`.<br>\n",
    "2. Define table 2 using `STORED AS PARQUET`.<br>\n",
    "3. Load the data into table 1.<br>\n",
    "4. Insert/select the data from table 1 to table 2.<br>\n",
    "5. Hive is commonly used for data conversion.<br>\n",
    "</details>\n",
    "\n",
    "\n",
    "Text vs Binary\n",
    "--------------\n",
    "\n",
    "Should I use a text or a binary format?\n",
    "\n",
    "- Text is human readable but inefficient at scale.\n",
    "\n",
    "Avro vs Parquet vs ORC\n",
    "----------------------\n",
    "\n",
    "Which binary format should I use?\n",
    "\n",
    "- The optimal data format depends on nature of your data.\n",
    "\n",
    "- Parquet and ORC (Optimized Row Columnar) are columnar, and are good\n",
    "  for \"narrow\" data.\n",
    "\n",
    "- Narrow means the data has few columns and the rows are repetitive. \n",
    "\n",
    "- Avro is non-columnar and is good for unstructured \"wide\" data.\n",
    "\n",
    "- Wide means the data has lots of columns and each row is different.\n",
    "\n",
    "Parquet vs ORC\n",
    "--------------\n",
    "\n",
    "Between ORC and Parquet which one should I use?\n",
    "\n",
    "- ORC and Parquet are competing industry standards. Like Betamax and\n",
    "  VHS.\n",
    "\n",
    "- Parquet is more popular overall.\n",
    "\n",
    "- According to [research][ibm-parquet] from IBM in September 2014 ORC\n",
    "  uses less storage but Parquet has faster query times.\n",
    "\n",
    "[ibm-parquet]: https://developer.ibm.com/hadoop/blog/2014/09/19/big-sql-3-0-file-formats-usage-performance/\n",
    "\n",
    "![](images/ibm-data-format-comparison.jpg)\n",
    "\n",
    "\n",
    "RC File\n",
    "-------\n",
    "\n",
    "What is the RC File format?\n",
    "\n",
    "- RC (Record Columnar) is an older version of ORC (Optimized Row Columnar).\n",
    "\n",
    "SequenceFiles\n",
    "-------------\n",
    "\n",
    "When should I use SequenceFiles?\n",
    "\n",
    "- SequenceFiles are a binary format used by MapReduce that stores data\n",
    "  as key-value pairs.\n",
    "\n",
    "- Useful for storing intermediate data between a chain of MapReduce\n",
    "  jobs.\n",
    "\n",
    "- Easy to use in programs.\n",
    "\n",
    "- Unlike other binary formats, SequenceFiles only work with Java.\n",
    "\n",
    "<!-- \n",
    "\n",
    "Spark SQL vs Hive vs Impala vs Tez vs Shark, Phoenix, Trifidion, Presto, Drill\n",
    "\n",
    "Left Semi Join \n",
    "  `LEFT SEMI JOIN`       |Like `JOIN` but `SELECT` only references left table\n",
    "\n",
    "Join Conditions\n",
    "\n",
    "  Can I join on other conditions besides equality?\n",
    "\n",
    "  - Hive only allows joining on equality.\n",
    "\n",
    "Operators\n",
    "\n",
    "File Formats\n",
    "\n",
    "Writing Data\n",
    "\n",
    "Moving Data With Insert/Select\n",
    "\n",
    "Insert\n",
    "\n",
    "Clustering\n",
    "\n",
    "Bucketing\n",
    "\n",
    "Sorting\n",
    "\n",
    "Optimizing Joins\n",
    "\n",
    "Altering Tables\n",
    "\n",
    "Views\n",
    "\n",
    "\n",
    "-->"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
